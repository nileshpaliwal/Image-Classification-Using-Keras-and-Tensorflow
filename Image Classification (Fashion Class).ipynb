{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #1: IMPORTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd # Import Pandas for data manipulation using dataframes\n",
    "import numpy as np # Import Numpy for data statistical analysis \n",
    "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes creation for both training and testing datasets \n",
    "fashion_train_df = pd.read_csv('input/fashion-mnist_train.csv',sep=',')\n",
    "fashion_test_df = pd.read_csv('input/fashion-mnist_test.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #2: VISUALIZATION OF THE DATASET  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the head of the training dataset\n",
    "# 784 indicates 28x28 pixels and 1 coloumn for the label\n",
    "# After you check the tail, 60,000 training dataset are present\n",
    "fashion_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the last elements in the training dataset\n",
    "fashion_train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the head of the testing dataset\n",
    "fashion_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the last elements in the testing dataset\n",
    "fashion_test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing arrays\n",
    "training = np.array(fashion_train_df, dtype = 'float32')\n",
    "testing = np.array(fashion_test_df, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view some images!\n",
    "i = random.randint(1,60000) # select any random index from 1 to 60,000\n",
    "plt.imshow( training[i,1:].reshape((28,28)) ) # reshape and plot the image\n",
    "\n",
    "plt.imshow( training[i,1:].reshape((28,28)) , cmap = 'gray') # reshape and plot the image\n",
    "\n",
    "\n",
    "# Remember the 10 classes decoding is as follows:\n",
    "# 0 => T-shirt/top\n",
    "# 1 => Trouser\n",
    "# 2 => Pullover\n",
    "# 3 => Dress\n",
    "# 4 => Coat\n",
    "# 5 => Sandal\n",
    "# 6 => Shirt\n",
    "# 7 => Sneaker\n",
    "# 8 => Bag\n",
    "# 9 => Ankle boot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = training[i,0]\n",
    "label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view more images in a grid format\n",
    "# Define the dimensions of the plot grid \n",
    "W_grid = 15\n",
    "L_grid = 15\n",
    "\n",
    "# fig, axes = plt.subplots(L_grid, W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific figures at various locations\n",
    "\n",
    "fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n",
    "\n",
    "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
    "\n",
    "n_training = len(training) # get the length of the training dataset\n",
    "\n",
    "# Select a random number from 0 to n_training\n",
    "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n",
    "\n",
    "    # Select a random number\n",
    "    index = np.random.randint(0, n_training)\n",
    "    # read and display an image with the selected index    \n",
    "    axes[i].imshow( training[index,1:].reshape((28,28)) )\n",
    "    axes[i].set_title(training[index,0], fontsize = 8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# Remember the 10 classes decoding is as follows:\n",
    "# 0 => T-shirt/top\n",
    "# 1 => Trouser\n",
    "# 2 => Pullover\n",
    "# 3 => Dress\n",
    "# 4 => Coat\n",
    "# 5 => Sandal\n",
    "# 6 => Shirt\n",
    "# 7 => Sneaker\n",
    "# 8 => Bag\n",
    "# 9 => Ankle boot\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #3: TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare the training and testing dataset \n",
    "X_train = training[:,1:]/255\n",
    "y_train = training[:,0]\n",
    "\n",
    "X_test = testing[:,1:]/255\n",
    "y_test = testing[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * unpack the tuple\n",
    "X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n",
    "X_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # open source Neural network library madke our life much easier\n",
    "\n",
    "# y_train = keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from scikit library\n",
    "# Import Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "# Try 32 fliters first then 64\n",
    "cnn_model.add(Conv2D(64,3, 3, input_shape = (28,28,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "# cnn_model.add(Conv2D(32,3, 3, activation='relu'))\n",
    "# cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "cnn_model.add(Dense(output_dim = 10, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = cnn_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size = 512,\n",
    "                        nb_epoch = epochs,\n",
    "                        verbose = 1,\n",
    "                        validation_data = (X_validate, y_validate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #4: EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = cnn_model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy : {:.3f}'.format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = cnn_model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5\n",
    "W = 5\n",
    "fig, axes = plt.subplots(L, W, figsize = (12,12))\n",
    "axes = axes.ravel() # \n",
    "\n",
    "for i in np.arange(0, L * W):  \n",
    "    axes[i].imshow(X_test[i].reshape(28,28))\n",
    "    axes[i].set_title(\"Prediction Class = {:0.1f}\\n True Class = {:0.1f}\".format(predicted_classes[i], y_test[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize = (14,10))\n",
    "sns.heatmap(cm, annot=True)\n",
    "# Sum the diagonal element to get the total true correct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_classes = 10\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "\n",
    "print(classification_report(y_test, predicted_classes, target_names = target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
